# ğŸ¥ Intelligent Medical Q&A Chatbot (RAG + LangChain)



An AI-powered chatbot that answers **medical questions** using **Retrieval-Augmented Generation (RAG)** with **LangChain**, **FAISS semantic search**, and integrates with both **LM Studio (local)** and **OpenAI (cloud)**. It retrieves information from trusted medical sources like **WHO, NHS, CDC, MedlinePlus, and Mayo Clinic** to provide reliable and context-aware responses.


---

## ğŸš€ Features

- ğŸ” **FAISS Vector Search** â€“ Retrieves relevant medical information from indexed sources  
- ğŸ¤– **Hybrid LLM Integration** â€“ Works with LM Studio locally or OpenAI in the cloud  
- ğŸ› ï¸ **Flask Backend** â€“ Lightweight API for query handling  
- ğŸ¨ **Frontend UI** â€“ Simple HTML/CSS interface for asking medical questions
---

## ğŸ› ï¸ Installation

### 1. Extract Project Files
```
bashunzip Medical-Chatbot-RAG.zip
cd Medical-Chatbot-RAG
```

### 2. Create Virtual Environment
```bash
python -m venv venv
```

### 3. Activate Virtual Environment
```bash
# Windows
.\venv\Scripts\activate
```

### 4. Install Dependencies
```bash
pip install -r requirements.txt
```
Or manually:
```bash
pip install langchain langchain-community pypdfloader langchain-text-splitters sentence-transformers faiss-cpu flask openai
```

### 5. Initialize Vector Store
```bash
python back.py
```
This creates the `ipc_index/` folder containing the FAISS vector store.

---

## âš™ï¸ Configure LLM (Choose One)

**Option A: LM Studio (Local)**  
- Download and run LM Studio  
- Load your preferred LLM model  
- Start the local inference server (default: `http://127.0.0.1:1234`)  

**Option B: OpenAI (Cloud)**  
- Replace the OpenAI client code in `app.py` with:
```python
client = OpenAI(api_key="your-openai-key")
```

---

## â–¶ï¸ Run the Application
```bash
python app.py
```
Then open [http://localhost:5000](http://localhost:5000) in your browser.

---

## ğŸ’¬ Usage
-Enter a medical question (e.g., "What are the early symptoms of diabetes?")
-The system retrieves relevant documents and generates a context-based answer
- Example output:  
  *"Common early symptoms of diabetes include frequent urination, increased thirst, and fatigue (WHO, NHS)."*

---

## ğŸ“ Project Structure
```
Medical-Chatbot-RAG/
â”œâ”€â”€ app.py              # Flask application
â”œâ”€â”€ back.py             # FAISS vector store initialization
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html      # Homepage UI
â”‚   â””â”€â”€ answer.html     # Answer display UI
â”œâ”€â”€ medical_index/      # FAISS vector store (auto-generated)
â”œâ”€â”€ project_images/     # Screenshots (homepage.png, answer.png)
â”œâ”€â”€ requirements.txt    # Dependencies
â””â”€â”€ README.md           # This file

```

---

## ğŸ§© Troubleshooting
- **FAISS Errors** â€“ Use Python 3.8+ and compatible `faiss-cpu`  
- **LM Studio Issues** â€“ Ensure local server is running at `http://127.0.0.1:1234`  
- **OpenAI Errors** â€“ Check your API key and internet connection  

---

